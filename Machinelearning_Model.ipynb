{"cells":[{"cell_type":"code","source":["%run ./Failure_Data_Analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bca9c63-f79e-4cdf-b97d-d3228380b59b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import LogisticRegression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef2a0fa8-6021-4570-ad39-33f1bb81a649"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Prepare the Training data\n\nA fundamental practice in machine learning is to calibrate and test your model parameters on data that has not been used to train the model.\n\n\nEvaluation of the model requires splitting the available data into a training portion, a calibration portion and an evaluation portion.\n\nFor splitting we are using time dependent splitting because we want to train our model based on time pattern of failure. random splitting doesnt work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31a461eb-69e4-4786-8955-943de01cf385"}}},{"cell_type":"code","source":["#Prepare the Training and Testing data\n\n# We'll use the known label, and key variables.\nlabel_var = ['label_e']\nkey_cols =['machineID','df_time']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1150958b-26a5-4cad-abb7-3a9ad0395bd0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# get the remaing feature names from the data\ninput_features = labeled_features.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c56b7807-07cf-49ea-b837-61bcd759504f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# remove unwanted columns\nremove_names = label_var + key_cols + ['failure','model_encoded','model']\ndisplay(remove_names)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f0c1082-62e4-4568-b557-e8fe7d0e15fa"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Remove the extra names if that are in the input_features list\ninput_features = [x for x in input_features if x not in set(remove_names)]\ndisplay(input_features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41cad363-a84b-4f43-8337-a2d96aa12ef2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["the dataset here and then split the data into a training and test set.\nWe use this split data to train the model on 9 months of data (training data), and evaluate on the remaining 3 months (test data) going forward"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d76c5a74-4086-47ef-a490-f1cc746e2f84"}}},{"cell_type":"code","source":["# assemble features\nva = VectorAssembler(inputCols=(input_features), outputCol='features')\nlabeled_features = va.transform(labeled_features).select('machineID','df_time','label_e','features')\ndisplay(labeled_features)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67be76d5-a077-48fc-99ba-5534f793756d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# set maxCategories so features with > 10 distinct values are treated as continuous.\nfeatureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=10).fit(labeled_features)\ndisplay(featureIndexer)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90617df2-58bd-4b90-bb87-dcab1d3b34b3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# fit on whole dataset to include all labels in index\nlabelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(labeled_features)\ndisplay(labelIndexer)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddbdafcb-012a-4590-a458-a274a2c980c9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# split the data into train/test based on date\nsplit_date = \"2015-10-30\"\ntraining = labeled_features.filter(labeled_features.df_time < split_date)\ntesting =  labeled_features.filter(labeled_features.df_time >= split_date)\ndisplay(training)\ndisplay(testing)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77e7b6b6-cf3b-4dc3-8781-c2d8fed134b5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Here i am using 3 machine learning algorithms"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ac5af26-a7e4-4a39-b857-e807ea388070"}}},{"cell_type":"code","source":["model = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",maxDepth=15,\n                                      maxBins=32,minInstancesPerNode=1,minInfoGain=0.0,impurity=\"gini\")\n\n# chain indexers and model in a Pipeline\npipeline_cls_mthd = Pipeline(stages=[labelIndexer, featureIndexer, model])\n\n# train model.  This also runs the indexers.\nmodel_pipeline = pipeline_cls_mthd.fit(training)\n\n# make predictions. The Pipeline does all the same operations on the test data\npredictions = model_pipeline.transform(testing)\n\n# confusion matrix for the multiclass prediction results\nconf_table = predictions.stat.crosstab('indexedLabel', 'prediction')\n\nconfuse = conf_table.toPandas()\n\n# True positives - diagonal failure terms \ntp = confuse['1.0'][1]+confuse['2.0'][2]+confuse['3.0'][3]+confuse['4.0'][4]\n\n# False positves - All failure terms - True positives\nfp = np.sum(np.sum(confuse[['1.0', '2.0','3.0','4.0']])) - tp\n\n# True negatives \ntn = confuse['0.0'][0]\n\n# False negatives total of non-failure column - TN\nfn = np.sum(np.sum(confuse[['0.0']])) - tn\n\n# Accuracy is diagonal/total \nacc_n = tn + tp\nacc_d = np.sum(np.sum(confuse[['0.0','1.0', '2.0','3.0','4.0']]))\nacc = acc_n/acc_d\n\n# Calculate precision and recall.\nprec = tp/(tp+fp)\nrec = tp/(tp+fn)\n\n# Print the evaluation metrics\ndisplay(confuse)\nprint(\"Accuracy = %g\" % acc)\nprint(\"Precision = %g\" % prec)\nprint(\"Recall = %g\" % rec )\nprint(\"F1 = %g\" % (2.0 * prec * rec/(prec + rec)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94a9c2d3-4d19-48f5-b27b-2d7b4345b1a9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",maxIter=10)\n\n# chain indexers and model in a Pipeline\npipeline_cls_mthd = Pipeline(stages=[labelIndexer, featureIndexer, model])\n\n# train model.  This also runs the indexers.\nmodel_pipeline = pipeline_cls_mthd.fit(training)\n\n# make predictions. The Pipeline does all the same operations on the test data\npredictions = model_pipeline.transform(testing)\n\n# confusion matrix for the multiclass prediction results\nconf_table = predictions.stat.crosstab('indexedLabel', 'prediction')\n\nconfuse = conf_table.toPandas()\n\n# True positives - diagonal failure terms \ntp = confuse['1.0'][1]+confuse['2.0'][2]+confuse['3.0'][3]+confuse['4.0'][4]\n\n# False positves - All failure terms - True positives\nfp = np.sum(np.sum(confuse[['1.0', '2.0','3.0','4.0']])) - tp\n\n# True negatives \ntn = confuse['0.0'][0]\n\n# False negatives total of non-failure column - TN\nfn = np.sum(np.sum(confuse[['0.0']])) - tn\n\n# Accuracy is diagonal/total \nacc_n = tn + tp\nacc_d = np.sum(np.sum(confuse[['0.0','1.0', '2.0','3.0','4.0']]))\nacc = acc_n/acc_d\n\n# Calculate precision and recall.\nprec = tp/(tp+fp)\nrec = tp/(tp+fn)\n\n# Print the evaluation metrics\ndisplay(confuse)\nprint(\"Accuracy = %g\" % acc)\nprint(\"Precision = %g\" % prec)\nprint(\"Recall = %g\" % rec )\nprint(\"F1 = %g\" % (2.0 * prec * rec/(prec + rec)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c00cff8-a549-40e5-9b0e-9d70e5b2e8dd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",maxDepth=15,maxBins=32,minInstancesPerNode=1,minInfoGain=0.0,impurity=\"gini\",numTrees=50,featureSubsetStrategy=\"sqrt\",subsamplingRate = 0.632)\n\n# chain indexers and model in a Pipeline\npipeline_cls_mthd = Pipeline(stages=[labelIndexer, featureIndexer, model])\n\n# train model.  This also runs the indexers.\nmodel_pipeline = pipeline_cls_mthd.fit(training)\n\n# make predictions. The Pipeline does all the same operations on the test data\npredictions = model_pipeline.transform(testing)\n\n# confusion matrix for the multiclass prediction results\nconf_table = predictions.stat.crosstab('indexedLabel', 'prediction')\n\nconfuse = conf_table.toPandas()\n\n# True positives - diagonal failure terms \ntp = confuse['1.0'][1]+confuse['2.0'][2]+confuse['3.0'][3]+confuse['4.0'][4]\n\n# False positves - All failure terms - True positives\nfp = np.sum(np.sum(confuse[['1.0', '2.0','3.0','4.0']])) - tp\n\n# True negatives \ntn = confuse['0.0'][0]\n\n# False negatives total of non-failure column - TN\nfn = np.sum(np.sum(confuse[['0.0']])) - tn\n\n# Accuracy is diagonal/total \nacc_n = tn + tp\nacc_d = np.sum(np.sum(confuse[['0.0','1.0', '2.0','3.0','4.0']]))\nacc = acc_n/acc_d\n\n# Calculate precision and recall.\nprec = tp/(tp+fp)\nrec = tp/(tp+fn)\n\n# Print the evaluation metrics\ndisplay(confuse)\nprint(\"Accuracy = %g\" % acc)\nprint(\"Precision = %g\" % prec)\nprint(\"Recall = %g\" % rec )\nprint(\"F1 = %g\" % (2.0 * prec * rec/(prec + rec)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afa4ab0d-358c-43e9-a36a-f8d4e0d15de5"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Machinelearning_Model","dashboards":[],"language":"python","widgets":{},"notebookOrigID":2958893554226352}},"nbformat":4,"nbformat_minor":0}
